{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1\n",
    "\n",
    "Пчелкина Ю.Ж., группа 6231-010402D\n",
    "\n",
    "Лабораторную работу необходимо выполнять в ***Google Colab***. Результат работы (в виде ссылки на notebook) выслать письмом на litvinov.vg@ssau.ru. В теме письма указывать ФИО полностью.\n",
    "\n",
    "Для выполнения задания необходимо подобрать корпус текстов (художественных) на английском языке. Объем корпуса должен составлять не менее $3 \\cdot 10^7$ символов. Далее все действия будут выполняться над выбранными данными. Для отладки алгоритмов лучше использовать не весь корпус, а лишь его часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код загрузки корпуса (только для чтения)\n",
    "file = open('WarAndPeace.txt', 'r')\n",
    "file_text = file.read()\n",
    "# закрыли файл\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №1\n",
    "Заменить все числа, которые представлены цифрами, их текстовым представлением (т.е. прописью). (1 = one, 23 = twenty three, 1042 = one thousand forty two, и т.п.). Методы библиотек не использовать, алгоритм необходимо написать самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = {0: '', 1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight', 9: 'nine'}\n",
    "\n",
    "teens = {10: 'ten', 11: 'eleven', 12: 'twelve', 13: 'thirteen', 14: 'fourteen', 15: 'fifteen', \n",
    "               16: 'sixteen', 17: 'seventeen', 18: 'eighteen', 19: 'nineteen'}\n",
    "\n",
    "decades = {2: 'twenty', 3: 'thirty', 4: 'forty', 5: 'fifty', 6: 'sixty', 7: 'seventy', 8: 'eighty', 9: 'ninety'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_word(number):\n",
    "    \n",
    "    l = len(number)\n",
    "    num = int(number)\n",
    "\n",
    "    if l == 1: \n",
    "        word = ones[num]\n",
    "           \n",
    "    elif l == 2:\n",
    "        if num < 20: word = teens[num]\n",
    "        else:\n",
    "            i, j = divmod(num, 10)\n",
    "            word = decades[i] + ' ' + ones[j]\n",
    "    \n",
    "    elif l == 3:\n",
    "        k, m = divmod(num, 100)\n",
    "        word_end = number_to_word(str(m))\n",
    "        word = ones[k] + ' handred ' + word_end\n",
    "    \n",
    "    else:\n",
    "        if l < 7:\n",
    "            k = l - 3\n",
    "            word_begin = number[0: k]\n",
    "            word_end = number[k: l]\n",
    "            word = number_to_word(word_begin) + ' thousand ' + number_to_word(word_end)\n",
    "        elif l < 10:\n",
    "            k = l - 6\n",
    "            word_begin = number[0: k]\n",
    "            word_end = number[k: l]\n",
    "            word = number_to_word(word_begin) + ' million ' + number_to_word(word_end)\n",
    "        else:\n",
    "            word = number\n",
    "        \n",
    "    return(str(word))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WarAndPeace.txt', 'r') as f1, open('new.txt', 'w') as f2:\n",
    "    lines = [line for line in f1]\n",
    "    for line in lines:\n",
    "        flag = False\n",
    "        word = ''\n",
    "        for ch in line:\n",
    "            if ch.isnumeric():\n",
    "                flag = True\n",
    "                word += ch\n",
    "            else:\n",
    "                if flag:\n",
    "                    flag = False\n",
    "                    new_word = number_to_word(word)\n",
    "                    f2.write(new_word)\n",
    "                    f2.write(ch)\n",
    "                else:\n",
    "                    f2.write(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №2\n",
    "Преобразовать текст к нижнему или верхнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('new.txt', 'r')\n",
    "text = f1.read()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new.txt', 'w') as f2:\n",
    "    for line in text:\n",
    "        line = line.lower()\n",
    "        f2.write(line) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №3\n",
    "Произвести токенезацию (токенами выступают слова), не учитывая знаки препинания (т.е. необходимо разбить текст на токены (лексемы)):\n",
    "* С помощью nltk.tokenize.RegexpTokenizer (тут необходимо вспомнить регулярные выражения [posix](https://ru.wikibooks.org/wiki/%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "with open('new.txt', 'r') as f2:\n",
    "    r_token = tokenizer.tokenize(f2.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* С помощью nltk.word_tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new.txt', 'r') as f2:\n",
    "    w_token = word_tokenize(f2.read())\n",
    "    \n",
    "w_token = [tok for tok in w_token if tok not in punctuation]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №4\n",
    "Произвести частотный анализ слов. Методы библиотек не использовать, т.е. алгоритм необходимо написать самостоятельно. Cохранить результат в выходной csv файл в порядке убывания частот. Формат выходного файла:\n",
    "\n",
    "| Word | Count |\n",
    "| --- | --- |\n",
    "| cat | 1000 |\n",
    "| dog | 300 |\n",
    "| .... | .... |\n",
    "| butterfly | 34 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>8130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>4950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>3761.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>3054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>2614.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word   Count\n",
       "0  the  8130.0\n",
       "1  and  4950.0\n",
       "2   to  3761.0\n",
       "3   of  3054.0\n",
       "4    a  2614.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_word = []\n",
    "list_word_count = []\n",
    "count = 0\n",
    "\n",
    "for word in r_token:\n",
    "    if word not in list_word:\n",
    "        list_word.append(word)\n",
    "        list_word_count.append({'Word': word, 'Count': 1})\n",
    "    else:\n",
    "        for i in range(len(list_word)):\n",
    "            if list_word_count[i]['Word'] == word:\n",
    "                list_word_count[i]['Count'] += 1\n",
    "\n",
    "# создаем пустой дата-фрем\n",
    "df_title = {'Word': [], 'Count': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "\n",
    "# в датафрейм добавляем данные\n",
    "df = df.append(list_word_count)   \n",
    "df_word = df.sort_values(by = 'Count', ascending = False)\n",
    "\n",
    "\n",
    "df_word.to_csv('df_word.csv', index = False)\n",
    "\n",
    "df_word = pd.read_csv('df_word.csv')\n",
    "df_word.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №5\n",
    "Произвести частотный анализ [N-грам](https://en.wikipedia.org/wiki/N-gram) и сохранить в выходной файл в порядке убывания частот (формат файла аналогичен предыдущему примеру, за исключением столбца Word, который заменяется на N-gram. В этой задаче можно использовать готовые библиотеки (смотрим состав библиотеки [NLTK](https://www.nltk.org/)). Формат выходного файла:\n",
    "\n",
    "| bigram | | Count |\n",
    "| --- | --- | --- |\n",
    "| cat | is | 1000 |\n",
    "| is | a | 300 |\n",
    "| .... | .... | .... |\n",
    "| the | fish | 34 |\n",
    "\n",
    "* Биграм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigramm</th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prince</td>\n",
       "      <td>andrew</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bigramm          Count\n",
       "0      of     the  849.0\n",
       "1      to     the  570.0\n",
       "2      in     the  524.0\n",
       "3  prince  andrew  349.0\n",
       "4     and     the  347.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramms = list(nltk.bigrams(r_token))\n",
    "\n",
    "list_bigramm = []\n",
    "list_bigramm_count = []\n",
    "count = 0\n",
    "\n",
    "for bigramm in bigramms:\n",
    "    if bigramm not in list_bigramm:\n",
    "        list_bigramm.append(bigramm)\n",
    "        list_bigramm_count.append({'Bigramm': bigramm[0], '  ': bigramm[1], 'Count': 1})\n",
    "    else:\n",
    "        for i in range(len(list_bigramm)):\n",
    "            if list_bigramm_count[i]['Bigramm'] == bigramm[0] and list_bigramm_count[i]['  '] == bigramm[1]:\n",
    "                list_bigramm_count[i]['Count'] += 1\n",
    "\n",
    "# создаем пустой дата-фрем\n",
    "df_title = {'Bigramm': [], '  ': [], 'Count': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "\n",
    "# в датафрейм добавляем данные\n",
    "df = df.append(list_bigramm_count)   \n",
    "df_bigramm = df.sort_values(by = 'Count', ascending = False)\n",
    "\n",
    "df_bigramm.to_csv('df_bigramm.csv', index = False)\n",
    "\n",
    "df_bigramm = pd.read_csv('df_bigramm.csv')\n",
    "df_bigramm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3-грам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigramm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>don</td>\n",
       "      <td>t</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>commander</td>\n",
       "      <td>in</td>\n",
       "      <td>chief</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>commander</td>\n",
       "      <td>in</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Trigramm                    Count\n",
       "0          i        don      t   69.0\n",
       "1  commander         in  chief   59.0\n",
       "2        the  commander     in   57.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramms = list(nltk.trigrams(r_token))\n",
    "\n",
    "\n",
    "list_trigramm = []\n",
    "list_trigramm_count = []\n",
    "count = 0\n",
    "\n",
    "for trigramm in trigramms:\n",
    "    if trigramm not in list_trigramm:\n",
    "        list_trigramm.append(trigramm)\n",
    "        list_trigramm_count.append({'Trigramm': trigramm[0], \n",
    "                                    '  ': trigramm[1], '   ': trigramm[2], 'Count': 1})\n",
    "    else:\n",
    "        for i in range(len(list_trigramm)):\n",
    "            if list_trigramm_count[i]['Trigramm'] == trigramm[0] and list_trigramm_count[i]['  '] == trigramm[1] and list_trigramm_count[i]['   '] == trigramm[2]:\n",
    "                \n",
    "                list_trigramm_count[i]['Count'] += 1\n",
    "\n",
    "                \n",
    "# создаем пустой дата-фрем\n",
    "df_title = {'Trigramm': [], '  ': [], '   ': [], 'Count': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "\n",
    "# в датафрейм добавляем данные\n",
    "df = df.append(list_trigramm_count)   \n",
    "df_trigramm = df.sort_values(by = 'Count', ascending = False)\n",
    "\n",
    "df_trigramm.to_csv('df_trigramm.csv', index = False)\n",
    "\n",
    "df_trigramm = pd.read_csv('df_trigramm.csv')\n",
    "df_trigramm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №6 (аналогично шагу 3)\n",
    "Произвести токенезацию, но уже учитывая знаки препинания:\n",
    "* С помощью nltk.tokenize.RegexpTokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+|\\S+')\n",
    "\n",
    "with open('new.txt', 'r') as f2:\n",
    "    r1_token = tokenizer.tokenize(f2.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* С помощью nltk.word_tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new.txt', 'r') as f2:\n",
    "    w1_token = word_tokenize(f2.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №7 (аналогично шагу 4)\n",
    "Произвести частотный анализ слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>8524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>8040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>5514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>4833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>3746.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word   Count\n",
       "0    ,  8524.0\n",
       "1  the  8040.0\n",
       "2    .  5514.0\n",
       "3  and  4833.0\n",
       "4   to  3746.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_word = []\n",
    "list_word_count = []\n",
    "count = 0\n",
    "\n",
    "for word in r1_token:\n",
    "    if word not in list_word:\n",
    "        list_word.append(word)\n",
    "        list_word_count.append({'Word': word, 'Count': 1})\n",
    "    else:\n",
    "        for i in range(len(list_word)):\n",
    "            if list_word_count[i]['Word'] == word:\n",
    "                list_word_count[i]['Count'] += 1\n",
    "\n",
    "                \n",
    "                \n",
    "# создаем пустой дата-фрем\n",
    "df_title = {'Word': [], 'Count': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "\n",
    "# в датафрейм добавляем данные\n",
    "df = df.append(list_word_count)   \n",
    "df_word1 = df.sort_values(by = 'Count', ascending = False)\n",
    "\n",
    "df_word1.to_csv('df_word1.csv', index = False)\n",
    "\n",
    "df_word1 = pd.read_csv('df_word1.csv')\n",
    "df_word1.head()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №8 (аналогично шагу 5)\n",
    "Произвести частотный анализ N-грам.\n",
    "\n",
    "* Биграм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigramm</th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>1395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>847.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>the</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bigramm        Count\n",
       "0       ,  and  1395.0\n",
       "1      of  the   847.0\n",
       "2      to  the   565.0\n",
       "3       .  the   541.0\n",
       "4      in  the   523.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramms = list(nltk.bigrams(r1_token))\n",
    "\n",
    "list_bigramm = []\n",
    "list_bigramm_count = []\n",
    "count = 0\n",
    "\n",
    "for bigramm in bigramms:\n",
    "    if bigramm not in list_bigramm:\n",
    "        list_bigramm.append(bigramm)\n",
    "        list_bigramm_count.append({'Bigramm': bigramm[0], '  ': bigramm[1], 'Count': 1})\n",
    "    else:\n",
    "        for i in range(len(list_bigramm)):\n",
    "            if list_bigramm_count[i]['Bigramm'] == bigramm[0] and list_bigramm_count[i]['  '] == bigramm[1]:\n",
    "                list_bigramm_count[i]['Count'] += 1\n",
    "\n",
    "# создаем пустой дата-фрем\n",
    "df_title = {'Bigramm': [], '  ': [], 'Count': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "\n",
    "# в датафрейм добавляем данные\n",
    "df = df.append(list_bigramm_count)   \n",
    "df_bigramm1 = df.sort_values(by = 'Count', ascending = False)\n",
    "\n",
    "df_bigramm1.to_csv('df_bigramm1.csv', index = False)\n",
    "\n",
    "df_bigramm1 = pd.read_csv('df_bigramm1.csv')\n",
    "df_bigramm1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3-грам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigramm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,\"</td>\n",
       "      <td>said</td>\n",
       "      <td>the</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>prince</td>\n",
       "      <td>andrew</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trigramm                  Count\n",
       "0        ,     and     the  125.0\n",
       "1       ,\"    said     the   88.0\n",
       "2        .  prince  andrew   84.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import trigrams\n",
    "\n",
    "trigramms = list(nltk.trigrams(r1_token))\n",
    "\n",
    "\n",
    "list_trigramm = []\n",
    "list_trigramm_count = []\n",
    "count = 0\n",
    "\n",
    "for trigramm in trigramms:\n",
    "    if trigramm not in list_trigramm:\n",
    "        list_trigramm.append(trigramm)\n",
    "        list_trigramm_count.append({'Trigramm': trigramm[0], \n",
    "                                    '  ': trigramm[1], '   ': trigramm[2], 'Count': 1})\n",
    "    else:\n",
    "        for i in range(len(list_trigramm)):\n",
    "            if list_trigramm_count[i]['Trigramm'] == trigramm[0] and list_trigramm_count[i]['  '] == trigramm[1] and list_trigramm_count[i]['   '] == trigramm[2]:\n",
    "                \n",
    "                list_trigramm_count[i]['Count'] += 1\n",
    "\n",
    "                \n",
    "# создаем пустой дата-фрем\n",
    "df_title = {'Trigramm': [], '  ': [], '   ': [], 'Count': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "\n",
    "# в датафрейм добавляем данные\n",
    "df = df.append(list_trigramm_count)   \n",
    "df_trigramm1 = df.sort_values(by = 'Count', ascending = False)\n",
    "\n",
    "df_trigramm1.to_csv('df_trigramm1.csv', index = False)\n",
    "\n",
    "df_trigramm1 = pd.read_csv('df_trigramm1.csv')\n",
    "df_trigramm1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №9 (используя результаты 5-го шага)\n",
    "Произвести генерацию текста на основе частот биграм. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the\n",
      "and the emperor\n",
      "and the emperor s\n",
      "and the emperor s face\n",
      "and the emperor s face and\n",
      "and the emperor s face and the\n",
      "and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and\n",
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n"
     ]
    }
   ],
   "source": [
    "# на основе токенов без учета знаков препинания\n",
    "\n",
    "# самое популярное слово\n",
    "max_word = df_word['Word'][1]\n",
    "\n",
    "N = 50\n",
    "text_gen = ''\n",
    "\n",
    "# наиболее популярная биграмма с ним\n",
    "df = df_bigramm.copy()\n",
    "new_df = df.query('Bigramm == @max_word')\n",
    "new_df.to_csv('new_df.csv', index = False)\n",
    "new_df = pd.read_csv('new_df.csv')   \n",
    "\n",
    "new_word = new_df['  '][0]\n",
    "\n",
    "text_gen = text_gen + new_df['Bigramm'][0] + ' ' + new_df['  '][0]\n",
    "print(text_gen)\n",
    "\n",
    "for i in range(N):    \n",
    "    #if new_word in new_df['Bigramm']: \n",
    "    new_df = df.query('Bigramm == @new_word')\n",
    "    new_df.to_csv('new_df.csv', index = False)\n",
    "    new_df = pd.read_csv('new_df.csv')\n",
    "        \n",
    "    new_word = new_df['  '][0]\n",
    "    new_df = df.drop(labels = [0], axis = 0)\n",
    "        \n",
    "    text_gen = text_gen + ' ' + new_word\n",
    "    print(text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the emperor s face and the\n"
     ]
    }
   ],
   "source": [
    "print(text_gen)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
